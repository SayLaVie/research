Evolving a Hex-Playing Agent
Michael McCarver and Rob LeGrand, PhD

               Intro with related work:

Hex is an adversarial board game in which there is always exactly one winner. The game was invented in 1942 by Piet Hein, and independently reinvented in 1948 by John Nash. The board is in the shape of an nxn parralelogram and is made up of nxn hexagon shaped tiles. Each player has a store of tiles, colored differently than their opponents'. Players alternate placing tiles on the hexagons of the board, capturing that hexagon. The goal of the game is for a player to connect opposing sides of the board. The sides of the board each player is aiming to connect is determined before the game starts. See Figure 1 below for an example of a completed game. John Nash offered an existence proof in 1949 of a first-player advantage, but no general winning strategy exists for the game (Gardner).
   (picture of hex board)

Research into Hex is often concerned with solving the game. Here, solving generally means finding perfect moves that give the player a guaranteed win. Levels of 'solved' vary from knowing only the best first move (weakly solved), to knowing the best move at all points in the game (strongly solved). As of 2011, humans have only been able to solve some center moves weakly for boards sized 8x8 and 9x9 (Beyond Humans). In 2014, Pawlewicz and Hayward developed a Scalable Parallel DFPN Search and used it to solve all previously intractable 9x9 openings and one 10x10 opening. The hardest 9x9 opening took 111 days (Scalable Parallel DFPN Search).

Other avenues of research have been explored in the context of boardgame play. David Fogel trained a nerual network with an evolutionary algorithm to teach it to play checkers, with the goal of evolving a 'good' player. The neural network was accompanied with a minimax search of variable depth (Blondie 24). Young, Vasan, and Hayward used Deep Q-Learning and self-play to train a CNN (convolutional neural network) to play Hex on a 13x13 board with no search. They began the experiment with supervised training on *database of games?* in order to teach their program the basics of gameplay quickly (neurohex).
   **Do I need to go into detail about their results?**


               Experimental Setup:
Our research is inspired by the work of David Fogel in Blondie 24. We set out to evolve the weights of an ANN through genetic algorithm. One key difference between our research, however, is that at no point do we utilize a minimax search. Our 'populations' of experiments are completely blind to the game Hex, except for the fact that they can see whether or not a move is valid.


The purpose of this research is to:
   1) Create a strong Hex player that relies on an ANN (artificial neural network) to make evaluations of the state of a Hex board during any stage of play, so that minimax search strategies can be bypassed entirely.
   2) Evaluate the effects of the size and shape of ANN on the ability of the ANN to learn board evaluation
   3) Evaluate the effects of the evolutionary approaches of the genetic algorithm on the ability of the ANN to learn board evaluation

An exhaustive search with a minimax style algorithm yields perfect play, but the running time of such a search increases exponentially as board sizes grow.




               Experimental Results:




               Conclusions:







               Future Work:

Sources

Martin Gardner "Hexaflexagons, Probability Paradoxes, and the Tower of Hanoi" (might be a more appropriate citation media)

Scalable Parallel DFPN Search

Solving Hex: Beyond Humans

Blondie 24
